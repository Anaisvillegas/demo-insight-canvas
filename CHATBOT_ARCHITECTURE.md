# ARQUITECTURA DEL SISTEMA DE CHATBOT - DEMO INSIGHT CANVAS

## üìã RESUMEN EJECUTIVO

El sistema de chatbot en demo-insight-canvas es una aplicaci√≥n compleja que integra m√∫ltiples tecnolog√≠as para proporcionar una experiencia de chat inteligente con capacidades de generaci√≥n de artefactos, consultas a base de datos Memgraph, y renderizado de visualizaciones din√°micas.

## üèóÔ∏è ARQUITECTURA GENERAL

### **Componentes Principales:**
1. **Frontend React** - Interfaz de usuario del chat
2. **API Routes Next.js** - Endpoints del servidor
3. **Integraci√≥n LLM** - OpenAI/Anthropic para procesamiento de lenguaje
4. **Base de Datos Supabase** - Almacenamiento de mensajes y artefactos
5. **Memgraph** - Base de datos de grafos para consultas especializadas
6. **Sistema de Artefactos** - Generaci√≥n y renderizado de contenido din√°mico

## üîÑ FLUJO COMPLETO DEL CHATBOT

### **1. INICIO DE CONVERSACI√ìN**

```
Usuario accede ‚Üí ChatPanel se monta ‚Üí Carga contexto autom√°ticamente
```

**Archivos involucrados:**
- `components/chat/panel.tsx` (Componente principal)
- `app/api/context/route.ts` (Carga de contexto)

**Proceso:**
1. El `ChatPanel` se monta y detecta si es un chat nuevo o existente
2. Si es nuevo, carga contexto inmediatamente desde `/api/context`
3. Si es existente, obtiene mensajes de Supabase y verifica contexto

### **2. ENV√çO DE MENSAJE**

```
Usuario escribe ‚Üí Click "Enviar" ‚Üí handleSend() ‚Üí append() ‚Üí API /chat
```

**Flujo detallado:**

#### **A. Captura de Input (`components/chat/input.tsx`)**
```typescript
// Funci√≥n principal de env√≠o
const handleSend = async () => {
  const query = input.trim();
  if (!query) return;

  // Validaci√≥n de API keys
  if (settings.model === Models.claude && !settings.anthropicApiKey) {
    toast.error("Please enter your Claude API Key");
    return;
  }

  // Verificar y cargar contexto si es necesario
  if (!contextLoaded && !hasContextMessage(contextMessagesRef.current)) {
    await loadAndAddContext();
  }

  // Preparar attachments
  const messageAttachments = [
    ...attachments.filter(item => item.contentType?.startsWith("image")),
    ...selectedArtifacts.map(url => ({ url }))
  ];

  // Enviar mensaje usando hook useChat
  append({
    role: "user",
    content: query,
    experimental_attachments: messageAttachments,
  }, {
    body: {
      model: settings.model,
      apiKey: settings.model.startsWith("gpt") 
        ? settings.openaiApiKey 
        : settings.anthropicApiKey,
      experimental_attachments: messageAttachments,
    },
  });
}
```

#### **B. Procesamiento en API (`app/api/chat/route.ts`)**

**Flujo de procesamiento:**

1. **Recepci√≥n de datos:**
```typescript
const { messages: originalMessages, apiKey, model } = await req.json();
```

2. **Configuraci√≥n del LLM:**
```typescript
// Selecci√≥n del modelo (OpenAI o Anthropic)
if (model === Models.claude || model === Models.claude35Sonnet) {
  const anthropic = createAnthropic({ apiKey });
  llm = anthropic(model);
} else if (model.startsWith("gpt")) {
  const openai = createOpenAI({ apiKey });
  llm = openai(model);
}
```

3. **Preparaci√≥n de mensajes:**
```typescript
const coreMessages: CoreMessage[] = [
  ...convertToCoreMessages(initialMessages),
  {
    role: "user",
    content: [
      { type: "text", text: currentMessage.content },
      ...imageParts, // Attachments de im√°genes
    ],
  },
];
```

4. **Primera llamada al LLM:**
```typescript
const result = await streamText({
  model: llm,
  messages: coreMessages,
  system: ArtifactoSystemPrompt,
  ...options,
});
```

5. **Detecci√≥n de consultas Memgraph:**
```typescript
// Buscar patrones de consulta Memgraph en la respuesta
const memgraphQueryMatch = fullResponse.match(/<memgraph_query>([\s\S]*?)<\/memgraph_query>/);

if (memgraphQueryMatch && memgraphQueryMatch[1]) {
  const cypherQuery = memgraphQueryMatch[1].trim();
  
  try {
    // Ejecutar consulta Cypher
    const queryResults = await executeCypherQuery(cypherQuery);
    
    // Segunda llamada al LLM con resultados
    const secondResult = await streamText({
      model: llm,
      messages: [...coreMessages, 
        { role: 'assistant', content: fullResponse },
        { role: 'system', content: `Results: ${JSON.stringify(queryResults)}` }
      ],
      system: ArtifactoSystemPrompt,
    });
    
    return secondResult.toAIStreamResponse();
  } catch (error) {
    // Manejo de errores de Memgraph
  }
}
```

### **3. PROCESAMIENTO DE RESPUESTA**

#### **A. System Prompt (`app/api/chat/systemPrompt.ts`)**

**Caracter√≠sticas principales:**
- **Detecci√≥n de consultas Memgraph:** Identifica cu√°ndo necesita datos de la base de grafos
- **Generaci√≥n de artefactos:** Crea contenido HTML, React, SVG, etc.
- **Manejo de contexto:** Utiliza informaci√≥n contextual de artifacts
- **Restricciones de datos:** NUNCA simula datos, solo usa datos reales de Memgraph

**Ejemplo de instrucci√≥n para Memgraph:**
```
When a user's question requires information from the knowledge base:
1. Formulate a Cypher query
2. Output: `<memgraph_query>YOUR_CYPHER_QUERY_HERE</memgraph_query>`
3. STOP your response
```

#### **B. Streaming de respuesta**
```typescript
// El LLM retorna un stream que se env√≠a al cliente
return result.toAIStreamResponse();
```

### **4. RENDERIZADO DE MENSAJES**

#### **A. Lista de mensajes (`components/chat/message-list.tsx`)**
```typescript
// Filtra mensajes de contexto y renderiza solo mensajes de usuario/asistente
const visibleMessages = messages.filter(message => {
  const metadata = message.metadata as any;
  return message.message_type !== "context" && 
         !(metadata?.isContext);
});
```

#### **B. Mensaje individual (`components/chat/message.tsx`)**
- Detecta y renderiza artefactos
- Maneja attachments de im√°genes
- Aplica formato markdown

### **5. GESTI√ìN DE CONTEXTO**

#### **A. Carga autom√°tica de contexto (`components/chat/panel.tsx`)**
```typescript
const loadAndAddContext = async () => {
  // Prevenir m√∫ltiples cargas simult√°neas
  if (loadingContextRef.current || contextLoaded) return;
  
  loadingContextRef.current = true;
  
  try {
    // Obtener contexto desde API
    const contextData = await fetchContext();
    
    if (contextData) {
      // Crear mensaje de contexto
      const contextMessage: Message = {
        id: `context-${Date.now()}`,
        role: "user",
        content: contextData,
        message_type: "context",
        metadata: { isContext: true }
      };
      
      // Guardar en BD si existe chatId
      if (chatId) {
        await addMessage(supabase, chatId, contextMessage);
      }
      
      // Actualizar estado local
      setMessages(prev => [contextMessage, ...prev]);
    }
  } finally {
    loadingContextRef.current = false;
    setContextLoaded(true);
  }
};
```

#### **B. API de contexto (`app/api/context/route.ts`)**

**Funciones principales:**
1. **Extracci√≥n de artifacts:** Busca artifacts tipo "master" en Supabase
2. **Procesamiento de datos:** Convierte JSON o extrae datos de APIs
3. **Creaci√≥n de contexto:** Genera informaci√≥n contextual para el LLM
4. **Fallback:** Crea artifacts de ejemplo si no existen datos

```typescript
// Buscar artifacts master
const { data: masterArtifacts } = await supabase
  .from("artifacts")
  .select("*")
  .eq("type", "master")
  .eq("user_id", user.id);

// Procesar cada artifact
for (const artifact of masterArtifacts) {
  if (isReactCode(artifact.code)) {
    // Extraer datos de APIs desde c√≥digo React
    const apiData = await extractApiDataFromReactCode(artifact.code);
    dataByType[artifact.name] = apiData;
  } else if (isValidJSON(artifact.code)) {
    // Procesar como JSON directo
    const content = safeJSONParse(artifact.code);
    dataByType[artifact.name] = content;
  }
}
```

### **6. CREACI√ìN DE CHATS**

#### **A. Detecci√≥n de nuevo chat**
```typescript
useEffect(() => {
  const createNewChat = async () => {
    // Crear chat cuando hay 1 respuesta del asistente y no est√° generando
    if (!chatId && 
        messages.filter(msg => msg.role === 'assistant').length === 1 && 
        !generatingResponse) {
      
      if (!startChatCreation()) return; // Prevenir duplicaci√≥n
      
      try {
        const title = userMessage?.content.slice(0, 100) || 'Nuevo Chat';
        
        // Incluir contexto si existe
        const messagesToSave = hasContextMessage(messages) 
          ? messages 
          : [contextMessage, ...messages];
          
        createChatMutation.mutate({ title, messages: messagesToSave });
      } finally {
        finishChatCreation();
      }
    }
  };
  
  createNewChat();
}, [chatId, messages, generatingResponse]);
```

#### **B. Mutaci√≥n de creaci√≥n**
```typescript
const createChatMutation = useMutation({
  mutationFn: async ({ title, messages }) => 
    await createChat(supabase, title, session?.user.id),
  
  onSuccess: async (newChat, { messages }) => {
    // Actualizar cache de React Query
    queryClient.setQueryData(["chats"], oldChats => 
      [...(oldChats || []), newChat]);
    
    // Guardar mensajes en BD
    for (const message of messages) {
      await addMessage(supabase, newChat.id, message);
    }
    
    // Actualizar URL y notificar
    setChatId(newChat.id);
    if (onChatCreated) {
      onChatCreated(newChat.id);
      window.history.pushState({ chatId: newChat.id }, '', 
        `/artifact-workspace?chat=${newChat.id}`);
    }
  },
});
```

## üîß COMPONENTES T√âCNICOS DETALLADOS

### **1. Hooks y Estado**

#### **A. useChat (AI SDK)**
```typescript
const {
  messages,
  input,
  setInput,
  append,
  setMessages,
  stop: stopGenerating,
  isLoading: generatingResponse,
} = useChat({
  initialMessages,
  onFinish: async (message) => {
    if (chatId) {
      await addMessage(supabase, chatId, message);
    }
  },
  sendExtraMessageFields: true,
});
```

#### **B. Estado de contexto**
```typescript
const [contextLoaded, setContextLoaded] = useState(false);
const contextMessagesRef = useRef<Message[]>([]);
const contextLoadedRef = useRef(false);
const loadingContextRef = useRef(false);
```

#### **C. Control de creaci√≥n de chat**
```typescript
const [chatCreated, setChatCreated] = useState(false);
const chatCreationInProgressRef = useRef(false);

const startChatCreation = useCallback(() => {
  const chatInProgress = localStorage.getItem('chatCreationInProgress');
  if (chatInProgress || chatCreationInProgressRef.current || chatCreated) {
    return false; // Prevenir duplicaci√≥n
  }
  
  localStorage.setItem('chatCreationInProgress', 'true');
  chatCreationInProgressRef.current = true;
  return true;
}, [chatCreated]);
```

### **2. Integraci√≥n con Memgraph**

#### **A. Servicio Memgraph (`lib/memgraphService.ts`)**
```typescript
export async function executeCypherQuery(query: string) {
  try {
    const response = await fetch(MEMGRAPH_ENDPOINT, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Basic ${MEMGRAPH_AUTH}`,
      },
      body: JSON.stringify({ query }),
    });
    
    const data = await response.json();
    return data.results;
  } catch (error) {
    console.error('Error executing Cypher query:', error);
    throw error;
  }
}
```

#### **B. Tipos de consultas soportadas**
- **KPIMortality:** Datos de mortalidad
- **KPIFeedConsumption:** Consumo de alimento
- **KPIAnimalWeight:** Peso de animales
- **KPIConversionRate:** Tasas de conversi√≥n
- **KPITemperatureSummary:** Datos de temperatura

### **3. Sistema de Attachments**

#### **A. Manejo de archivos**
```typescript
const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
  if (e.target.files) {
    const filesArray = Array.from(e.target.files);
    const newAttachments = await Promise.all(
      filesArray.map(async (file) => ({
        url: await convertFileToBase64(file),
        name: file.name,
        contentType: file.type,
      }))
    );
    onAddAttachment(newAttachments);
  }
};
```

#### **B. Captura de artefactos**
```typescript
const handleCapture: ReactArtifactProps["onCapture"] = ({
  selectionImg,
  artifactImg,
}) => {
  setAttachments(prev => [...prev, {
    contentType: "image/png",
    url: selectionImg,
  }]);
  
  setSelectedArtifacts(prev => {
    if (prev.includes(artifactImg)) return prev;
    return [...prev, artifactImg];
  });
};
```

### **4. Integraci√≥n con Whisper (Voz)**

#### **A. Configuraci√≥n dual**
```typescript
// Hook real de Whisper (con API key)
const realWhisperResult = useRealWhisper({
  apiKey: settings.openaiApiKey || 'dummy-key',
  onTranscribe: hasOpenAIKey ? undefined : async () => Promise.resolve({ text: '' }),
});

// Hook fake de Whisper (sin API key)
const fakeWhisperResult = useFakeWhisper();

// Usar el apropiado seg√∫n disponibilidad de API key
const { recording, transcribing, transcript, startRecording, stopRecording } = 
  hasOpenAIKey ? realWhisperResult : fakeWhisperResult;
```

#### **B. Actualizaci√≥n de input con transcripci√≥n**
```typescript
useEffect(() => {
  if (!recording && !transcribing && transcript?.text) {
    setInput(prev => prev + ` ${transcript.text}`);
  }
}, [recording, transcribing, transcript?.text, setInput]);
```

## üöÄ CARACTER√çSTICAS AVANZADAS

### **1. Feature Flags**
```typescript
// Configuraci√≥n de caracter√≠sticas del chatbot
const featureFlags = {
  OPTIMIZED_CHATBOT: false,
  CHAT_QUEUE: false,
  CHAT_CACHE: false,
  CHAT_LAZY_LOADING: false,
  CHAT_METRICS: false
};
```

### **2. Manejo de Errores**
- **Timeouts:** 300 segundos para consultas Memgraph
- **Fallbacks:** Respuestas de error cuando Memgraph falla
- **Validaci√≥n:** Verificaci√≥n de API keys antes de env√≠o

### **3. Optimizaciones de Performance**
- **Lazy loading:** Carga diferida de componentes
- **Memoizaci√≥n:** Componentes React memoizados
- **Streaming:** Respuestas en tiempo real del LLM
- **Caching:** Cache de consultas React Query

## üìä M√âTRICAS Y MONITOREO

### **A. Logs de Debug**
```typescript
console.log("üöÄ Feature flags cargados:", featureFlags);
console.log("‚öôÔ∏è Configuraci√≥n del renderizador:", config);
console.log("‚úÖ Contexto obtenido correctamente!!");
```

### **B. Estados de carga**
- `fetchingMessages`: Cargando mensajes existentes
- `generatingResponse`: Generando respuesta del LLM
- `contextLoaded`: Contexto cargado correctamente
- `chatCreated`: Chat creado exitosamente

## üîí SEGURIDAD Y VALIDACI√ìN

### **1. Autenticaci√≥n**
```typescript
const { supabase, session } = useSupabase();
if (!session?.user) {
  // Redirigir a login
}
```

### **2. Validaci√≥n de API Keys**
```typescript
if (settings.model === Models.claude && !settings.anthropicApiKey) {
  toast.error("Please enter your Claude API Key");
  return;
}
```

### **3. Sanitizaci√≥n de datos**
- Validaci√≥n JSON antes de parsing
- Escape de caracteres especiales
- Verificaci√≥n de tipos de archivo

## üéØ PUNTOS DE OPTIMIZACI√ìN IDENTIFICADOS

### **1. Timeouts y Delays**
- **Timeout API:** 300 segundos (muy alto)
- **Debounce input:** No implementado
- **Rate limiting:** No implementado

### **2. Sistema de Cola**
- **Feature flag:** `CHAT_QUEUE: false`
- **Implementaci√≥n:** Pendiente
- **Beneficio:** Manejo de m√∫ltiples requests

### **3. Cache de Chat**
- **Feature flag:** `CHAT_CACHE: false`
- **Implementaci√≥n:** Pendiente
- **Beneficio:** Respuestas m√°s r√°pidas

### **4. M√©tricas de Chat**
- **Feature flag:** `CHAT_METRICS: false`
- **Implementaci√≥n:** Pendiente
- **Beneficio:** An√°lisis de performance

## üìù CONCLUSIONES

El sistema de chatbot de demo-insight-canvas es una implementaci√≥n robusta que integra:

‚úÖ **Fortalezas:**
- Integraci√≥n completa con LLMs (OpenAI/Anthropic)
- Sistema de contexto autom√°tico
- Consultas din√°micas a Memgraph
- Generaci√≥n de artefactos avanzada
- Manejo de attachments y voz
- Prevenci√≥n de duplicaci√≥n de chats

‚ö†Ô∏è **√Åreas de mejora:**
- Implementar sistema de cola para requests
- Activar cache de chat para mejor performance
- Reducir timeouts excesivos
- Implementar m√©tricas de monitoreo
- A√±adir rate limiting
- Optimizar lazy loading de chat

üîß **Recomendaciones t√©cnicas:**
1. Activar feature flags de optimizaci√≥n gradualmente
2. Implementar debounce en input para reducir requests
3. A√±adir m√©tricas de tiempo de respuesta
4. Crear sistema de fallback para Memgraph
5. Implementar cache inteligente de contexto
